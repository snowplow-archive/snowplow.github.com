<!DOCTYPE html>
<html>
<head>
	
	<title>Snowplow 0.7.6 released with Redshift data warehouse support - Snowplow Analytics</title>
	

	<link rel="icon" type="image/x-icon" href="/favicon.ico" />

	<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
	<meta name="description" content="" />
	<link href="/static/css/styles.css" type="text/css" rel="stylesheet" />
	<link href="/static/css/pygments.css" type="text/css" rel="stylesheet" />
	
	<!--For the homepage slider-->
	<link rel="stylesheet" href="/static/css/nivo-slider.css" type="text/css" media="screen" />
	<link rel="stylesheet" href="/static/css/nivo-slider-theme-default.css" type="text/css" media="screen" />
	<script src="//ajax.googleapis.com/ajax/libs/jquery/1.9.0/jquery.min.js"></script>
	<script src="/static/js/jquery-nivo-slider-pack.js" type="text/javascript" ></script>
	<!--MathJax http://www.mathjax.org/-->
	<script type="text/javascript" src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-MML-AM_HTMLorMML.js"></script>
	<script type="text/javascript">
		MathJax.Hub.Config({
	      tex2jax: {
	        skipTags: ['script', 'noscript', 'style', 'textarea', 'pre']
	      }
	    });
	    MathJax.Hub.Queue(function() {
	        var all = MathJax.Hub.getAllJax(), i;
	        for(i=0; i < all.length; i += 1) {
	            all[i].SourceElement().parentNode.className += ' has-jax';
	        }
    	});
	</script>
	<!-- end mathjax -->
	<!-- typekit -->
	<script type="text/javascript" src="//use.typekit.net/noo1diw.js"></script>
	<script type="text/javascript">try{Typekit.load();}catch(e){}</script>
	<!-- end typekit -->
</head>
<body>
	<!-- Google Tag Manager -->
	<noscript><iframe src="//www.googletagmanager.com/ns.html?id=GTM-DLRG"
	height="0" width="0" style="display:none;visibility:hidden"></iframe></noscript>
	<script>(function(w,d,s,l,i){w[l]=w[l]||[];w[l].push({'gtm.start':
	new Date().getTime(),event:'gtm.js'});var f=d.getElementsByTagName(s)[0],
	j=d.createElement(s),dl=l!='dataLayer'?'&l='+l:'';j.async=true;j.src=
	'//www.googletagmanager.com/gtm.js?id='+i+dl;f.parentNode.insertBefore(j,f);
	})(window,document,'script','dataLayer','GTM-DLRG');</script>
	<!-- End Google Tag Manager -->
	<div id="universe">
		<div id="container">
			<div id="header" class="span-24">
  <div id="logo">
    <h1><a href="/"><img src="/static/img/snowplow-logo-website.png" title="Snowplow Analytics" /></a></h1>
  </div>
  <div id="menu" class="span-15">
    <ul>
      <li ><a href="/product/index.html">Product</a></li>
      <li ><a href="/services/index.html">Services</a></li>
      <li ><a href="/analytics/index.html">Analytics</a></li>
      <li ><a href="/technology/index.html">Technology</a></li>
      <li  class="active" ><a href="/blog.html">Blog</a></li>
      <li ><a id="mail" href="/about/index.html">About</a></li>
    </ul>
  </div>
</div>
	
			<div id="contents">
		<div class="post">
			03 Mar 2013
			<h1>Snowplow 0.7.6 released with Redshift data warehouse support</h1>
			 <span class="author">Author: <a href="/alex.html" rel="author">Alex Dean </a></span>
			<p>We&#8217;re excited to announce the immediate release of Snowplow version <strong>0.7.6</strong> with support for storing your Snowplow events in <a href='http://aws.amazon.com/redshift/'>Amazon Redshift</a>.</p>

<p>We were very excited when Amazon announced Redshift back in late 2012, and we have been working to integrate Snowplow data since Redshift became generally available two weeks ago. Our tests with Redshift since launch have not disappointed - and we can&#8217;t wait to see what the Snowplow community do with the new platform!</p>

<p>In this post we will cover:</p>

<ol>
<li><a href='/blog/2013/03/03/snowplow-0.7.6-released-with-redshift-data-warehouse-support#why-redshift'>Why Redshift is a great fit for Snowplow data</a></li>

<li><a href='/blog/2013/03/03/snowplow-0.7.6-released-with-redshift-data-warehouse-support#this-version'>Changes in this version</a></li>

<li><a href='/blog/2013/03/03/snowplow-0.7.6-released-with-redshift-data-warehouse-support#snowplow-redshift'>Setting up Snowplow for Redshift</a></li>

<li><a href='/blog/2013/03/03/snowplow-0.7.6-released-with-redshift-data-warehouse-support#upgrading'>Upgrading for Infobright/Hive users</a></li>

<li><a href='/blog/2013/03/03/snowplow-0.7.6-released-with-redshift-data-warehouse-support#roadmap'>Roadmap and next steps</a></li>

<li><a href='/blog/2013/03/03/snowplow-0.7.6-released-with-redshift-data-warehouse-support#help'>Getting help</a></li>
</ol>

<p>Read on below the fold to find out more.</p>
<!--more--><h2><a name='why-redshift'>1. Why Amazon Redshift is a great fit for Snowplow data</a></h2>
<p>Snowplow datasets get big very quickly: we store at least one line of data for every single event that occurs on your website or application. Our largest users are recording 100M+ events every day; these data volumes get very big, very quickly.</p>

<p>Whereas traditional web analytics packages deal with this by aggregating data to feed pre-cut reports, we built Snowplow specifically to maintain that granularity, because that granularity is critical to:</p>

<ul>
<li>Performing bespoke analyses e.g. analysing conversion rates by product, or segmenting users by behavior</li>

<li>Joining Snowplow data with third party datasets e.g. from your CMS, CRM, adserver or marketing data</li>
</ul>

<p>As a result, we built Snowplow on technologies like Hadoop and Hive from the get-go to enable Snowplow users to record and analyse massive volumes of event data.</p>

<p>The trouble with Hadoop and Hive is that they are not great tools for <a href='http://en.wikipedia.org/wiki/Online_analytical_processing'>OLAP analysis</a>. As a result, we added support for <a href='http://www.infobright.com/'>Infobright Community Edition</a>: an open source columnar database you deploy yourself which scales to terabytes.</p>

<p>With <a href='http://aws.amazon.com/redshift/'>Amazon Redshift</a>, we now support a columnar database that scales to petabytes. Not only that, but:</p>

<ul>
<li>Amazon Redshift is a fully managed service. Unlike Infobright, you do not need to setup and run your own servers: you simply connect to AWS and ask Amazon to fire up a Redshift cluster for you</li>

<li>Redshift clusters can easily be scaled up and down over time with your data requirements: it is simple to add and remove nodes; you can even snapshot and hibernate them</li>

<li>A wide range of analytics tools can be plugged directly into Redshift via well supported PostgreSQL JDBC and ODBC drivers. It already works with <a href='http://chartio.com/'>Chartio</a>. A dedicated connectors for Tableau is currently in development</li>

<li>Redshift supports a broader set of SQL functionality than Infobright. In particular, loading data into Redshift is much more straightforward, and debugging errors when they occur much easier</li>

<li>Data can be loaded directly from S3 into Redshift, making the Snowplow ETL pipeline simpler and more efficient. And support for loading Redshift directly from Elastic MapReduce is in Amazon&#8217;s roadmap</li>

<li>Redshift is part of the AWS cloud, around which Snowplow has been built</li>

<li>Redshift is highly cost-effective: costing as little $1,000 per TB per year</li>
</ul>

<p>Please read on to find out how to get started with Snowplow and Redshift.</p>
<h2><a name='this-version'>2. Changes in this version</a></h2>
<p>This version makes a set of changes to Snowplow to add support for Redshift; it is important to understand these changes even if you are using our Hive or Infobright storage options and are not interested in using Redshift.</p>

<p>The main changes are as follows:</p>

<ul>
<li>The HiveQL scripts have been renamed to align with the three storage formats they generate: <code>mysql-infobright</code>, <code>hive</code> and <code>redshift</code>.</li>

<li>EmrEtlRunner and StorageLoader have both been upgraded, to versions 0.0.9 and 0.0.5 respectively</li>

<li>The configuration file formats for EmrEtlRunner and StorageLoader have been updated to add support for Redshift and reflect the new naming conventions</li>
</ul>

<p>Additionally we have fixed two bugs in this version:</p>

<ol>
<li>Our Bash files for automating EmrEtlRunner and/or StorageLoader had a bug where the <code>BUNDLE_GEMFILE</code> configuration lines did not end in <code>/Gemfile</code>. This has now been fixed. Many thanks to <a href='https://github.com/EZWrighter'>Eric Zimmerman</a> for reporting this!</li>

<li>We have widened the field storing the raw useragent string in Infobright (and Redshift) to 1000 characters: 500 characters wasn&#8217;t enough</li>
</ol>

<p>If you are a Snowplow Hive/Infobright user with no interest in Redshift, please jump to <a href='FIXME#hive-ice-upgrade'>Upgrading for Infobright/Hive users</a> for information on how to upgrade.</p>
<h2><a name='snowplow-redshift'>3. Setting up Snowplow for Redshift</a></h2>
<p>This is a relatively simple process, which is fully documented on our wiki:</p>

<ol>
<li><a href='https://github.com/snowplow/snowplow/wiki/setting-up-redshift'>Setup a Redshift cluster</a></li>

<li><a href='https://github.com/snowplow/snowplow/wiki/1-Installing-EmrEtlRunner'>Configure EmrEtlRunner to output Snowplow events in Redshift format</a></li>

<li><a href='https://github.com/snowplow/snowplow/wiki/1-Installing-the-StorageLoader'>Configure StorageLoader to load Snowplow events into Redshift</a></li>

<li>(Optional) <a href='https://github.com/snowplow/snowplow/wiki/Setting-up-ChartIO-to-visualize-Snowplow-data#wiki-redshift'>Connect Chartio to Snowplow data in Redshift</a></li>
</ol>

<p>Once you have completed these steps, you should now have a Snowplow eventstream data warehouse setup in Redshift!</p>
<h2><a name='upgrading'>4. Upgrading for Infobright/Hive users</a></h2>
<p>These are the steps to upgrade Snowplow to version 0.7.6 if you are using the Hive or Infobright output formats:</p>

<h3 id='41_emretlrunner'>4.1 EmrEtlRunner</h3>

<p>If you are using EmrEtlRunner, you need to update your configuration file, <code>config.yml</code>, to use the latest versions of the Hive serde and HiveQL scripts:</p>

<pre><code>:snowplow:
  :serde_version: 0.5.5
  :hive_hiveql_version: 0.5.7
  :mysql_infobright_hiveql_version: 0.0.8
  :redshift_hiveql_version: 0.0.1</code></pre>

<p>If you are outputting Snowplow events in Infobright format, you need to update this line too:</p>

<pre><code>:etl:
  ...
  :storage_format: mysql-infobright # Used to be &#39;non-hive&#39;</code></pre>

<h3 id='42_infobright_table_definition'>4.2 Infobright table definition</h3>

<p>If you are using Infobright Community Edition for analysis, you will need to update your table definition, because we have widened the <code>useragent</code> field.</p>

<p>To make this easier for you, we have created a script:</p>

<pre><code>4-storage/infobright-storage/migrate_to_008.sh</code></pre>

<p>Running this script will create a new table, <code>events_008</code> (version 0.0.8 of the Infobright table definition) in your <code>snowplow</code> database, copying across all your data from your existing <code>events</code> table, which will not be modified in any way.</p>

<h3 id='43_storageloader'>4.3 StorageLoader</h3>

<p>If you are using StorageLoader, you need to update your configuration file, <code>config.yml</code>, to the new format:</p>

<pre><code>:storage:
  :type:     infobright
  :host:     # Not used by Infobright
  :database: ADD IN HERE
  :port:     # Not used by Infobright
  :table:    events_008 # NOT &quot;events_007&quot; any more
  :username: ADD IN HERE
  :password: ADD IN HERE</code></pre>

<p>Note that the <code>table</code> field now points to the new <code>events_008</code> table created in section 4.2 above.</p>

<p>Done!</p>
<h2><a name='roadmap'>5. Roadmap and next steps</a></h2>
<p>We&#8217;re really excited about the opportunities for building web-scale, low-cost data warehouses for marketing and product analytics with Amazon Redshift, and we&#8217;re super-excited about all of the potential uses of Snowplow event data within these data warehouses. If you&#8217;re excited too, do <a href='mailto:sales@snowplowanalytics.com'>get in touch</a>!</p>

<p>Separately, this is the last planned release in the 0.7.x series. We&#8217;re already hard at work on the next release, which will see us swap out the current Hive-based ETL process for a more robust, performant and extensible Hadoop (Cascading/Scalding) ETL process.</p>

<p>To keep track of this new release, please sign up for our <a href='https://groups.google.com/forum/?fromgroups#!forum/snowplow-user'>mailing list</a> and checkout our <a href='https://github.com/snowplow/snowplow/wiki/Product-roadmap'>Roadmap</a>.</p>
<h2><a name='help'>6. Getting help</a></h2>
<p>As always, if you do run into any issues or don&#8217;t understand any of the above changes, please <a href='https://github.com/snowplow/snowplow/issues'>raise an issue</a> or get in touch with us via <a href='https://github.com/snowplow/snowplow/wiki/Talk-to-us'>the usual channels</a>.</p>
			<div class="author_summary">
				<h2>About the author</h2>
				<div class="author_image"><img src="https://lh6.googleusercontent.com/-4Ydq6ygNbgQ/AAAAAAAAAAI/AAAAAAAAAF4/SX2Fn3veqp4/s120-c/photo.jpg" /></div> <div class="author_spiel">
  <a href="/alex.html">Alex</a> is co-founder and technical lead at Snowplow Analytics. You can find in him on <a href="https://plus.google.com/u/0/113518635920914092796" rel="author">Google+</a>, <a href="https://twitter.com/alexatkeplar">Twitter</a> and <a href="http://uk.linkedin.com/in/alexdean">LinkedIn</a>.
</div>

			</div> 
			<div id="comments">
	<h2>Questions? Comments? Join the debate!</h2>
	 <div id="disqus_thread"></div>
        <script type="text/javascript">
            /* * * CONFIGURATION VARIABLES: EDIT BEFORE PASTING INTO YOUR WEBPAGE * * */
            var disqus_shortname = 'snowplow'; // required: replace example with your forum shortname
            /* var disqus_identifier =  ; // unique ID so that disqus fetches the correct comments for each post
            var disqus_url =  ;
            var disqus_title =  ; */

            /* * * DON'T EDIT BELOW THIS LINE * * */
            (function() {
                var dsq = document.createElement('script'); dsq.type = 'text/javascript'; dsq.async = true;
                dsq.src = 'http://' + disqus_shortname + '.disqus.com/embed.js';
                (document.getElementsByTagName('head')[0] || document.getElementsByTagName('body')[0]).appendChild(dsq);
            })();
        </script>
        <noscript>Please enable JavaScript to view the <a href="http://disqus.com/?ref_noscript">comments powered by Disqus.</a></noscript>
        <a href="http://disqus.com" class="dsq-brlink">comments powered by <span class="logo-disqus">Disqus</span></a>
</div>
		</div>
		<p>Return to the <a href="/blog.html">main blog page</a></p>
		

</div>

<div id="sidebar">
	<h1>Recent posts</h1>
	<ul>
		
			<li><a href="/blog/2014/02/04/snowplow-0.9.0-released-with-beta-kinesis-support">Snowplow 0.9.0 released with beta Amazon Kinesis support</a></li>
		
			<li><a href="/blog/2014/01/30/inaugural-amazon-kinesis-meetup">Inaugural meetup of the Amazon Kinesis - London User Group</a></li>
		
			<li><a href="/blog/2014/01/27/snowplow-javascript-tracker-0.13.0-released-with-custom-contexts">Snowplow JavaScript Tracker 0.13.0 released with custom contexts</a></li>
		
			<li><a href="/blog/2014/01/27/snowplow-custom-contexts-guide">A guide to custom contexts in Snowplow JavaScript Tracker 0.13.0</a></li>
		
			<li><a href="/blog/2014/01/21/snowplow-team-in-nyc-and-boston-in-feb-2014">The Snowplow team will be in New York and Boston in February - get in touch if you'd like to meet</a></li>
		
	</ul>

	
		<h1>Other</h1>
		<ul>
		
			
				<li><a href="/blog/2014/01/30/inaugural-amazon-kinesis-meetup">Inaugural meetup of the Amazon Kinesis - London User Group</a></li>
			
				<li><a href="/blog/2014/01/21/snowplow-team-in-nyc-and-boston-in-feb-2014">The Snowplow team will be in New York and Boston in February - get in touch if you'd like to meet</a></li>
			
				<li><a href="/blog/2013/12/04/snowplow-at-the-graduate-data-science-initiative">The first Graduate Data Science Initiative event in London</a></li>
			
				<li><a href="/blog/2013/11/11/round-up-and-thank-you-for-the-budapest-bi-conference-last-week">A round up of our trip to the Budapest BI Conference last week, and a thank you to the many people who made the trip so worthwhile</a></li>
			
				<li><a href="/blog/2013/10/28/yali-and-alex-introduce-snowplow-to-code-n">Our video introduction of Snowplow to code_n</a></li>
			
		
		</ul>		
	
		<h1>Releases</h1>
		<ul>
		
			
				<li><a href="/blog/2014/02/04/snowplow-0.9.0-released-with-beta-kinesis-support">Snowplow 0.9.0 released with beta Amazon Kinesis support</a></li>
			
				<li><a href="/blog/2014/01/27/snowplow-javascript-tracker-0.13.0-released-with-custom-contexts">Snowplow JavaScript Tracker 0.13.0 released with custom contexts</a></li>
			
				<li><a href="/blog/2014/01/27/snowplow-custom-contexts-guide">A guide to custom contexts in Snowplow JavaScript Tracker 0.13.0</a></li>
			
				<li><a href="/blog/2014/01/17/scala-forex-library-released">Scala Forex library by wintern Jiawen Zhou released</a></li>
			
				<li><a href="/blog/2014/01/08/snowplow-0.8.13-released-with-looker-support">Snowplow 0.8.13 released with Looker support</a></li>
			
		
		</ul>		
	
		<h1>Analytics</h1>
		<ul>
		
			
				<li><a href="/blog/2013/12/10/introducing-looker-a-fresh-approach-to-bi-on-snowplow-data">Introducing Looker - a fresh approach to Business Intelligence that works beautifully with Snowplow</a></li>
			
				<li><a href="/blog/2013/11/19/quickstart-guide-to-using-sql-with-snowplow-data-published">Quick start guide to learning SQL to query Snowplow data published</a></li>
			
				<li><a href="/blog/2013/10/28/call-for-data-this-winter">Call for data! Support us develop experimental analyses. Have us help you answer your toughest business questions.</a></li>
			
				<li><a href="/blog/2013/10/22/cohort-analysis-with-using-new-sql-recipes-and-chartio">Using the new SQL views to perform cohort analysis with ChartIO</a></li>
			
				<li><a href="/blog/2013/09/03/using-qubole-to-analyze-snowplow-web-data">Using Qubole to crunch your Snowplow web data using Apache Hive</a></li>
			
		
		</ul>		
	
		<h1>Inside the Plow</h1>
		<ul>
		
			
				<li><a href="/blog/2014/01/15/amazon-kinesis-tutorial-getting-started-guide">Amazon Kinesis tutorial - a getting started guide</a></li>
			
				<li><a href="/blog/2013/11/20/loading-json-data-into-redshift">Loading JSON data into Redshift - the challenges of quering JSON data, and how Snowplow can be used to meet those challenges</a></li>
			
				<li><a href="/blog/2013/09/27/how-much-does-snowplow-cost-to-run">How much does Snowplow cost to run, vs the competition?</a></li>
			
				<li><a href="/blog/2013/07/09/understanding-how-different-parts-of-the-Snowplow-data-pipeline-drive-AWS-costs">Unpicking the Snowplow data pipeline and how it drives AWS costs</a></li>
			
				<li><a href="/blog/2013/05/30/dealing-with-hadoops-small-files-problem">Dealing with Hadoop's small files problem</a></li>
			
		
		</ul>		
	
		<h1>Research</h1>
		<ul>
		
			
				<li><a href="/blog/2014/01/20/the-three-eras-of-business-data-processing">The three eras of business data processing</a></li>
			
				<li><a href="/blog/2013/10/21/scripting-hadoop-part-1-adventures-with-scala-rhino-and-javascript">Scripting Hadoop, Part One - Adventures with Scala, Rhino and JavaScript</a></li>
			
				<li><a href="/blog/2013/08/12/towards-universal-event-analytics-building-an-event-grammar">Towards universal event analytics - building an event grammar</a></li>
			
		
		</ul>		
	
		<h1>Recruitment</h1>
		<ul>
		
			
				<li><a href="/blog/2013/12/20/introducing-our-snowplow-winterns">Introducing our Snowplow winterns</a></li>
			
				<li><a href="/blog/2013/10/07/announcing-our-winter-open-source-internship-program">Announcing our winter open source internship program</a></li>
			
		
		</ul>		
	

	<h1>Useful links</h1>
	<ul>
		<li><a href="/blog/atom.xml">Atom feed</a></li>
	</ul>
	<!--<strong>Tags</strong> -->
</div>

			<div id="footer">
	<p>Copyright Â© Snowplow Analytics Limited 2012 - 2014.  All rights reserved</p>
</div>
		</div>
	</div>
		<!-- Following Javascript function used by Disqus to count the number of comments for each blog post and display in the main index -->
	  	<script type="text/javascript">
        /* * * CONFIGURATION VARIABLES: EDIT BEFORE PASTING INTO YOUR WEBPAGE * * */
        var disqus_shortname = 'snowplow'; // required: replace example with your forum shortname

        /* * * DON'T EDIT BELOW THIS LINE * * */
        (function () {
            var s = document.createElement('script'); s.async = true;
            s.type = 'text/javascript';
            s.src = 'http://' + disqus_shortname + '.disqus.com/count.js';
            (document.getElementsByTagName('HEAD')[0] || document.getElementsByTagName('BODY')[0]).appendChild(s);
        }());
        </script>
        <!-- begin olark code -->
		<script data-cfasync="false" type='text/javascript'>/*<![CDATA[*/window.olark||(function(c){var f=window,d=document,l=f.location.protocol=="https:"?"https:":"http:",z=c.name,r="load";var nt=function(){
		f[z]=function(){
		(a.s=a.s||[]).push(arguments)};var a=f[z]._={
		},q=c.methods.length;while(q--){(function(n){f[z][n]=function(){
		f[z]("call",n,arguments)}})(c.methods[q])}a.l=c.loader;a.i=nt;a.p={
		0:+new Date};a.P=function(u){
		a.p[u]=new Date-a.p[0]};function s(){
		a.P(r);f[z](r)}f.addEventListener?f.addEventListener(r,s,false):f.attachEvent("on"+r,s);var ld=function(){function p(hd){
		hd="head";return["<",hd,"></",hd,"><",i,' onl' + 'oad="var d=',g,";d.getElementsByTagName('head')[0].",j,"(d.",h,"('script')).",k,"='",l,"//",a.l,"'",'"',"></",i,">"].join("")}var i="body",m=d[i];if(!m){
		return setTimeout(ld,100)}a.P(1);var j="appendChild",h="createElement",k="src",n=d[h]("div"),v=n[j](d[h](z)),b=d[h]("iframe"),g="document",e="domain",o;n.style.display="none";m.insertBefore(n,m.firstChild).id=z;b.frameBorder="0";b.id=z+"-loader";if(/MSIE[ ]+6/.test(navigator.userAgent)){
		b.src="javascript:false"}b.allowTransparency="true";v[j](b);try{
		b.contentWindow[g].open()}catch(w){
		c[e]=d[e];o="javascript:var d="+g+".open();d.domain='"+d.domain+"';";b[k]=o+"void(0);"}try{
		var t=b.contentWindow[g];t.write(p());t.close()}catch(x){
		b[k]=o+'d.write("'+p().replace(/"/g,String.fromCharCode(92)+'"')+'");d.close();'}a.P(2)};ld()};nt()})({
		loader: "static.olark.com/jsclient/loader0.js",name:"olark",methods:["configure","extend","declare","identify"]});
		/* custom configuration goes here (www.olark.com/documentation) */
		olark.identify('9752-503-10-5227');/*]]>*/</script><noscript><a href="https://www.olark.com/site/9752-503-10-5227/contact" title="Contact us" target="_blank">Questions? Feedback?</a> powered by <a href="http://www.olark.com?welcome" title="Olark live chat software">Olark live chat software</a></noscript>
		<!-- end olark code -->
		<!-- Track Olark chats in GTM (so can pass data onto Snowplow) -->
		<script type="text/javascript">
		olark('api.chat.onMessageToOperator', function(event) {
		    dataLayer.push({'event': 'olarkMessageToOperator'});
		});
		olark('api.chat.onMessageToVisitor', function(event) {
		    dataLayer.push({'event': 'olarkMessageToVisitor'});
		});
		</script>
		<!-- end track olark code -->


</body>
</html>