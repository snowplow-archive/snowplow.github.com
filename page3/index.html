<!DOCTYPE html>
<html>
<head>
	
	<title></title>
	

	<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
	<link href="/static/css/styles.css" type="text/css" rel="stylesheet" />
	<link href="/static/css/pygments.css" type="text/css" rel="stylesheet" />
	

	<!--For the homepage slider-->
	<link rel="stylesheet" href="/static/css/nivo-slider.css" type="text/css" media="screen" />
	<link rel="stylesheet" href="/static/css/nivo-slider-theme-default.css" type="text/css" media="screen" />
	<script src="//ajax.googleapis.com/ajax/libs/jquery/1.9.0/jquery.min.js"></script>
	<script src="/static/js/jquery-nivo-slider-pack.js" type="text/javascript" ></script>
</head>
<body>
	<!-- Google Tag Manager -->
	<noscript><iframe src="//www.googletagmanager.com/ns.html?id=GTM-DLRG"
	height="0" width="0" style="display:none;visibility:hidden"></iframe></noscript>
	<script>(function(w,d,s,l,i){w[l]=w[l]||[];w[l].push({'gtm.start':
	new Date().getTime(),event:'gtm.js'});var f=d.getElementsByTagName(s)[0],
	j=d.createElement(s),dl=l!='dataLayer'?'&l='+l:'';j.async=true;j.src=
	'//www.googletagmanager.com/gtm.js?id='+i+dl;f.parentNode.insertBefore(j,f);
	})(window,document,'script','dataLayer','GTM-DLRG');</script>
	<!-- End Google Tag Manager -->

	<div id="container">
		<div id="header" class="span-24">
  <div id="logo">
    <h1><a href="/">Snowplow</a></h1>
    <p>Your web analytics data in your hands</p>
  </div>
  <div id="menu" class="span-15">
    <ul>
      <li ><a href="/product/index.html">Product</a></li>
      <li ><a href="/services/index.html">Services</a></li>
      <li ><a href="/analytics/index.html">Analytics</a></li>
      <li ><a href="/technology/index.html">Technology</a></li>
      <li  class="active" ><a href="/blog.html">Blog</a></li>
      <li ><a id="mail" href="/contact/index.html">Contact</a></li>
    </ul>
  </div>
</div>
	
		<div id="contents">
	
		<a name="Snowplow 0.7.4 released" />
		<div class="post">
			22 Feb 2013
			<h1><a href="/blog/2013/02/22/snowplow-0.7.4-released-for-better-eventstream-analytics">Snowplow 0.7.4 released for better eventstream analytics</a></h1>
			<p>Another week, another release! We&#8217;re excited to announce Snowplow version <strong>0.7.4</strong>. The primary purpose of this release is to clean up and rationalise our event data model, in particular around <strong>user IDs</strong> and <strong>event timestamps</strong>. This release should lay the foundations for more sophisticated eventstream analytics (such as funnel analysis), by:</p>

<ul>
<li>Enabling companies to assign custom user IDs (e.g. when a customer logs on)</li>

<li>Distinguish between IDs set at a domain level (via first-party cookies) and at a network level (via third-party cookies)</li>

<li>Enable precise ordering of events in a user&#8217;s click stream with accuracy correct to the milli-second</li>
</ul>

<p>Many thanks to Snowplow users <a href='http://www.simplybusiness.co.uk/'>Simply Business</a> and <a href='https://github.com/shermozle'>Simon Rumble</a> (APN) for suggesting many of these changes and helping us to design them.</p>

<p>In this post we will cover:</p>

<ol>
<li><a href='/blog/2013/02/22/snowplow-0.7.4-released-for-better-eventstream-analytics#user-ids'>Our new user IDs</a></li>

<li><a href='/blog/2013/02/22/snowplow-0.7.4-released-for-better-eventstream-analytics#event-tstamps'>Our new event timestamps</a></li>

<li><a href='/blog/2013/02/22/snowplow-0.7.4-released-for-better-eventstream-analytics#bug-fixes'>Bug fixes</a></li>

<li><a href='/blog/2013/02/22/snowplow-0.7.4-released-for-better-eventstream-analytics#deprecations'>Breaking changes</a></li>

<li><a href='/blog/2013/02/22/snowplow-0.7.4-released-for-better-eventstream-analytics#upgrading'>Upgrading</a></li>

<li><a href='/blog/2013/02/22/snowplow-0.7.4-released-for-better-eventstream-analytics#help'>Getting help</a></li>
</ol>

<p>Read on below the fold to find out more!</p>
<p class='more'><a href='/blog/2013/02/22/snowplow-0.7.4-released-for-better-eventstream-analytics'>Read the rest of this entry >></a></p>
			<span class="comments-link"><a href="/blog/2013/02/22/snowplow-0.7.4-released-for-better-eventstream-analytics#disqus_thread" rel="nofollow">View Comments</a></span>
		</div>
	
		<a name="Bulk loading data from Amazon S3 into Redshift at the command line" />
		<div class="post">
			20 Feb 2013
			<h1><a href="/blog/2013/02/20/transferring-data-from-s3-to-redshift-at-the-command-line">Bulk loading data from Amazon S3 into Redshift at the command line</a></h1>
			<p>On Friday Amazon launched <a href='http://aws.amazon.com/redshift/'>Redshift</a>, a fully managed, petabyte-scale data warehouse service. We&#8217;ve been busy since building out Snowplow support for Redshift, so that Snowplow users can use Redshift to store their granular, customer-level and event-level data for OLAP analysis.</p>

<p>In the course of building out Snowplow support for Redshift, we need to bulk load data stored in S3 into Redshift, programmatically. Unfortunately, the Redshift Java SDK is very slow at inserts, so not suitable bulk loading. We found a simple workaround that might be helpful for anyone who wishes to bulk load data into Redshift from S3, and have documented it below.</p>

<h2 id='an_overview_of_the_workaround'>An overview of the workaround</h2>

<p>Amazon enables users to bulk load data from S3 into Redshift by executing queries with the following form:</p>
<div class='highlight'><pre><code class='postgresql'><span class='k'>copy</span> <span class='n'>events</span> 
<span class='k'>from</span> <span class='s1'>&#39;s3://$MY-BUCKET/PATH/TO/FILES/FOR/UPLOAD&#39;</span> 
<span class='n'>credentials</span> <span class='s1'>&#39;aws_access_key_id=$ACCESS-KEY;aws_secret_access_key=$SECRET-ACCESS-KEY&#39;</span> 
<span class='k'>delimiter</span> <span class='s1'>&#39;\t&#39;</span><span class='p'>;</span>
</code></pre></div>
<p>However, these queries can only be executed in a SQL client running a JDBC or ODBC driver compatible with Redshift. (Links to those drivers can be found <a href='http://docs.aws.amazon.com/redshift/latest/gsg/before-you-begin.html#getting-started-download-tools'>here</a>. )</p>
<p class='more'><a href='/blog/2013/02/20/transferring-data-from-s3-to-redshift-at-the-command-line'>Read the rest of this entry >></a></p>
			<span class="comments-link"><a href="/blog/2013/02/20/transferring-data-from-s3-to-redshift-at-the-command-line#disqus_thread" rel="nofollow">View Comments</a></span>
		</div>
	
		<a name="Reflections on Saturday's Measurecamp" />
		<div class="post">
			18 Feb 2013
			<h1><a href="/blog/2013/02/18/ideas-coming-out-of-februarys-measurecamp">Reflections on Saturday's Measurecamp</a></h1>
			<p>On Satuday both Alex and I were lucky enough to attend London&#8217;s second <a href='http://www.measurecamp.org/'>Measurecamp</a>, an unconference dedicated to digital analytics. The venue was packed with smart people sharing some really interesting ideas - we can&#8217;t do justice to all those ideas here, so I&#8217;ve just outlined my favourite two from the day:</p>

<ol>
<li><a href='/blog/2013/02/18/ideas-coming-out-of-februarys-measurecamp#keywords'>Using keywords to segment audience by product and interest match</a>, courtesy of <a href='https://twitter.com/carmenmardiros'>Carmen Mardiros</a></li>

<li><a href='/blog/2013/02/18/ideas-coming-out-of-februarys-measurecamp#server-side-datalayer'>Transferring commercially sensitive data into your web analytics platform via a server-side dataLayer</a>, courtesy of <a href='https://twitter.com/TechPad'>Matt Clarke</a></li>
</ol>

<p>I&#8217;ve also post the slides I&#8217;d put together on <a href='/blog/2013/02/18/ideas-coming-out-of-februarys-measurecamp#clv'>customer lifetime value</a> for the event: I didn&#8217;t end up sharing these on the day, because the room where the session took place didn&#8217;t have a projector. That was just as well, as I think we had a much more interesting conversation about customer lifetime value as a result.</p>
<h2><a name='keywords'>1. Using keywords to segment audience by product and interest match</a></h2>
<p>In this rather excellent presentation, <a href='https://twitter.com/carmenmardiros'>Carmen</a> showed how you can use keywords users enter (either in searches directing them to your website, or on internal searches) to classify audience in especially meaningful buckets e.g.</p>

<ul>
<li>Are they already a customer?</li>

<li>Are they brand aware?</li>

<li>Are they looking to purchase vs looking for support?</li>

<li>Are they interested broadly or narrowly in your area?</li>
</ul>
<p class='more'><a href='/blog/2013/02/18/ideas-coming-out-of-februarys-measurecamp'>Read the rest of this entry >></a></p>
			<span class="comments-link"><a href="/blog/2013/02/18/ideas-coming-out-of-februarys-measurecamp#disqus_thread" rel="nofollow">View Comments</a></span>
		</div>
	
		<a name="Snowplow 0.7.3 released" />
		<div class="post">
			15 Feb 2013
			<h1><a href="/blog/2013/02/15/snowplow-0.7.3-released">Snowplow 0.7.3 released, tracking additional data</a></h1>
			<p>We&#8217;re excited to announce the release of Snowplow version <strong>0.7.3</strong>. This release adds a set of <strong>16 all-new fields</strong> to our event model:</p>

<ul>
<li>A new Event Vendor field</li>

<li>The Page URL split out into its component parts (scheme, host, port, path, querystring, fragment/anchor)</li>

<li>The web page&#8217;s character set</li>

<li>The web page&#8217;s width and height</li>

<li>The browser&#8217;s viewport (i.e. visible width and height)</li>

<li>For page pings, we are now tracking the user&#8217;s scrolling during the last ping period (four fields)</li>
</ul>

<p>These fields should make a new set of analyses on Snowplow data, including analysing how deeply users engage with different web pages (e.g. what percentage of a web page have they viewed, and how fast). In addition, it should make some analyses easier, e.g. aggregating (and comparing) metrics by page by page and domain.</p>

<p>In addition, the new release includes some minor bug fixes. In this post we will cover:</p>

<ol>
<li><a href='/blog/2013/02/15/snowplow-0.7.3-released#new-fields'>The new fields</a></li>

<li><a href='/blog/2013/02/15/snowplow-0.7.3-released#bug-fixes'>Bug fixes</a></li>

<li><a href='/blog/2013/02/15/snowplow-0.7.3-released#breaking-changes'>Breaking changes</a></li>

<li><a href='/blog/2013/02/15/snowplow-0.7.3-released#upgrade'>Upgrading</a></li>
</ol>
<h2><a name='new-fields'>1. New fields</a></h2>
<p>We are hugely excited to be including 16 new fields in this release - we believe that these fields should unlock a whole host of new analyses on Snowplow data.</p>

<p>For completeness, we list out all of the new fields below. Note that all of the new fields are available in both the S3 (aka Hive) and Infobright (aka non-Hive) storage outputs:</p>
<table><thead><tr><th>Field</th><th>Datatype</th><th>Description</th></tr></thead><tbody><tr><td style='text-align: left;'><code>event_vendor</code></td><td style='text-align: left;'>string</td><td style='text-align: left;'>Which company or org. defined this event type</td>
</tr><tr><td style='text-align: left;'><code>page_urlscheme</code></td><td style='text-align: left;'>string</td><td style='text-align: left;'>Scheme aka protocol, e.g. &#8220;https&#8221;</td>
</tr><tr><td style='text-align: left;'><code>page_urlhost</code></td><td style='text-align: left;'>string</td><td style='text-align: left;'>Host aka domain, e.g. &#8220;www.snowplowanalytics.com&#8221;</td>
</tr><tr><td style='text-align: left;'><code>page_urlport</code></td><td style='text-align: left;'>int</td><td style='text-align: left;'>Port if specified, 80 if not</td>
</tr><tr><td style='text-align: left;'><code>page_urlpath</code></td><td style='text-align: left;'>string</td><td style='text-align: left;'>Path to page, e.g. &#8220;/product/index.html&#8221;</td>
</tr><tr><td style='text-align: left;'><code>page_urlquery</code></td><td style='text-align: left;'>string</td><td style='text-align: left;'>Querystring, e.g. &#8220;id=GTM-DLRG&#8221;</td>
</tr><tr><td style='text-align: left;'><code>page_urlfragment</code></td><td style='text-align: left;'>string</td><td style='text-align: left;'>Fragment aka anchor, e.g. &#8220;4-conclusion&#8221;</td>
</tr><tr><td style='text-align: left;'><code>br_viewwidth</code></td><td style='text-align: left;'>integer</td><td style='text-align: left;'>The width of the browser&#8217;s viewport in pixels</td>
</tr><tr><td style='text-align: left;'><code>br_viewheight</code></td><td style='text-align: left;'>integer</td><td style='text-align: left;'>The height of the browser&#8217;s viewport in pixels</td>
</tr><tr><td style='text-align: left;'><code>doc_charset</code></td><td style='text-align: left;'>string</td><td style='text-align: left;'>The page&#8217;s character encoding, e.g. &#8220;UTF-8&#8221;</td>
</tr><tr><td style='text-align: left;'><code>doc_width</code></td><td style='text-align: left;'>integer</td><td style='text-align: left;'>The total width of the page (incl. non-viewed area)</td>
</tr><tr><td style='text-align: left;'><code>doc_height</code></td><td style='text-align: left;'>integer</td><td style='text-align: left;'>The total height of the page (incl. non-viewed area)</td>
</tr><tr><td style='text-align: left;'><code>pp_xoffset_min</code></td><td style='text-align: left;'>integer</td><td style='text-align: left;'>Minimum page x offset seen in the last ping period</td>
</tr><tr><td style='text-align: left;'><code>pp_xoffset_max</code></td><td style='text-align: left;'>integer</td><td style='text-align: left;'>Maximum page x offset seen in the last ping period</td>
</tr><tr><td style='text-align: left;'><code>pp_yoffset_min</code></td><td style='text-align: left;'>integer</td><td style='text-align: left;'>Minimum page y offset seen in the last ping period</td>
</tr><tr><td style='text-align: left;'><code>pp_yoffset_max</code></td><td style='text-align: left;'>integer</td><td style='text-align: left;'>Maximum page y offset seen in the last ping period</td>
</tr></tbody></table>
<p>Don&#8217;t worry if some of these new fields don&#8217;t make immediate sense based on the descriptions above - we will take a look at each of these fields in the sub-sections below:</p>
<p class='more'><a href='/blog/2013/02/15/snowplow-0.7.3-released'>Read the rest of this entry >></a></p>
			<span class="comments-link"><a href="/blog/2013/02/15/snowplow-0.7.3-released#disqus_thread" rel="nofollow">View Comments</a></span>
		</div>
	
		<a name="Writing Hive UDFs - a tutorial" />
		<div class="post">
			08 Feb 2013
			<h1><a href="/blog/2013/02/08/writing-hive-udfs-and-serdes">Writing Hive UDFs - a tutorial</a></h1>
			<p><em>Snowplow&#8217;s own <a href='https://github.com/alexanderdean'>Alexander Dean</a> was recently asked to write an article for the <a href='http://sdjournal.org/apache-hadoop-ecosystem/?a_aid=bartoszmiedeksza&amp;a_bid=45f0d439'>Software Developer&#8217;s Journal edition on Hadoop</a> The kind folks at the Software Developer&#8217;s Journal have allowed us to reprint his article in full below.</em></p>

<p><em>Alex started writing Hive UDFs as part of the process to write the <a href='https://github.com/snowplow/snowplow/tree/master/3-etl/hive-etl/snowplow-log-deserializers'>Snowplow log deserializer</a> - the custom SerDe used to parse Snowplow logs generated by the Cloudfront and Clojure collectors so they can be processed in the Snowplow ETL step.</em></p>

<h2 id='article_synopsis'>Article Synopsis</h2>

<p>In this article you will learn how to write a user-defined function (&#8220;UDF&#8221;) to work with the Apache Hive platform. We will start gently with an introduction to Hive, then move on to developing the UDF and writing tests for it. We will write our UDF in Java, but use Scala&#8217;s SBT as our build tool and write our tests in Scala with Specs2.</p>

<p>In order to get the most out of this article, you should be comfortable programming in Java. You do not need to have any experience with Apache Hive, HiveQL (the Hive query language) or indeed Hive UDFs - I will introduce all of these concepts from first principles. Experience with Scala is advantageous, but not necessary.</p>
<p class='more'><a href='/blog/2013/02/08/writing-hive-udfs-and-serdes'>Read the rest of this entry >></a></p>
			<span class="comments-link"><a href="/blog/2013/02/08/writing-hive-udfs-and-serdes#disqus_thread" rel="nofollow">View Comments</a></span>
		</div>
	

	<!-- Pagination links -->
	<div class="pagination">
		
			
			<a href="/page2" class="previous">Previous</a>
			
		
		<span class="page_number">Page: 3 of 11</span>
		
			<a href="/page4" class="next">Next</a>
		
	</div>
</div>

<div id="sidebar">
	<h1>Recent posts</h1>
	<ul>
		
			<li><a href="/blog/2013/04/23/performing-funnel-analysis-with-snowplow">Funnel analysis with Snowplow (Platform analytics part 1)</a></li>
		
			<li><a href="/blog/2013/04/18/measuring-content-page-performance-with-snowplow">Measuring content page performance with Snowplow (Catalog Analytics part 2)</a></li>
		
			<li><a href="/blog/2013/04/12/snowplow-0.8.1-released-with-referer-url-parsing">Snowplow 0.8.1 released with referer URL parsing</a></li>
		
			<li><a href="/blog/2013/04/12/online-catalog-analytics-with-snowplow">Measuring product page performance with Snowplow (Catalog Analytics part 1)</a></li>
		
			<li><a href="/blog/2013/04/10/snowplow-event-validation">Towards high-fidelity web analytics - introducing Snowplow's innovative new event validation capabilities</a></li>
		
	</ul>

	
		<h1>Other</h1>
		<ul>
		
			
				<li><a href="/blog/2013/02/20/transferring-data-from-s3-to-redshift-at-the-command-line">Bulk loading data from Amazon S3 into Redshift at the command line</a></li>
			
				<li><a href="/blog/2013/02/18/ideas-coming-out-of-februarys-measurecamp">Reflections on Saturday's Measurecamp</a></li>
			
				<li><a href="/blog/2013/01/21/working-out-what-data-to-pass-into-your-tag-manager">What data should you be passing into your tag manager?</a></li>
			
				<li><a href="/blog/2013/01/20/snowplow-hits-202-stars">Snowplow reaches 202 stars on GitHub</a></li>
			
				<li><a href="/blog/2013/01/18/using-snowplow-with-qubit-opentag">Implementing Snowplow with QuBit's OpenTag</a></li>
			
		
		</ul>		
	
		<h1>Releases</h1>
		<ul>
		
			
				<li><a href="/blog/2013/04/12/snowplow-0.8.1-released-with-referer-url-parsing">Snowplow 0.8.1 released with referer URL parsing</a></li>
			
				<li><a href="/blog/2013/04/10/snowplow-event-validation">Towards high-fidelity web analytics - introducing Snowplow's innovative new event validation capabilities</a></li>
			
				<li><a href="/blog/2013/04/03/snowplow-0.8.0-released-with-all-new-scalding-based-data-enrichment">Snowplow 0.8.0 released with all-new Scalding-based data enrichment</a></li>
			
				<li><a href="/blog/2013/03/25/snowplow-tracker-for-arduino-released-sensor-and-event-analytics-for-the-internet-of-things">Snowplow Arduino Tracker released - sensor and event analytics for the internet of things</a></li>
			
				<li><a href="/blog/2013/03/03/snowplow-0.7.6-released-with-redshift-data-warehouse-support">Snowplow 0.7.6 released with Redshift data warehouse support</a></li>
			
		
		</ul>		
	
		<h1>Analytics</h1>
		<ul>
		
			
				<li><a href="/blog/2013/04/23/performing-funnel-analysis-with-snowplow">Funnel analysis with Snowplow (Platform analytics part 1)</a></li>
			
				<li><a href="/blog/2013/04/18/measuring-content-page-performance-with-snowplow">Measuring content page performance with Snowplow (Catalog Analytics part 2)</a></li>
			
				<li><a href="/blog/2013/04/12/online-catalog-analytics-with-snowplow">Measuring product page performance with Snowplow (Catalog Analytics part 1)</a></li>
			
				<li><a href="/blog/2013/01/08/using-chartio-to-visualise-and-interrogate-snowplow-data">Using ChartIO to visualise and interrogate Snowplow data</a></li>
			
				<li><a href="/blog/2012/12/17/transforming-snowplow-data-so-it-can-be-interrogated-by-olap-tools-like-tableau">Transforming Snowplow data so that it can be interrogataed in BI / OLAP tools like Tableau, Qlikview and Pentaho</a></li>
			
		
		</ul>		
	
		<h1>Inside the Plow</h1>
		<ul>
		
			
				<li><a href="/blog/2013/03/20/rob-slifka-elasticity">Inside the Plow - Rob Slifka's Elasticity</a></li>
			
				<li><a href="/blog/2013/02/08/writing-hive-udfs-and-serdes">Writing Hive UDFs - a tutorial</a></li>
			
				<li><a href="/blog/2013/02/04/help-us-build-out-the-snowplow-event-model">Help us build out the Snowplow Event Model</a></li>
			
				<li><a href="/blog/2013/01/09/from-etl-to-enrichment">The Snowplow development roadmap for the ETL step - from ETL to enrichment</a></li>
			
				<li><a href="/blog/2013/01/07/the-clojure-collector-in-detail">Understanding the thinking behind the Clojure Collector, and mapping out its development going forwards</a></li>
			
		
		</ul>		
	
	

	<h1>Useful links</h1>
	<ul>
		<li><a href="/blog/atom.xml">Atom feed</a></li>
	</ul>
	<!--<strong>Tags</strong> -->
</div>
		<div id="footer">
	<p>Copyright Â© Snowplow Analytics Limited 2012 - 2013.  All rights reserved</p>
</div>
	</div>
	<!-- Following Javascript function used by Disqus to count the number of comments for each blog post and display in the main index -->
	  <script type="text/javascript">
        /* * * CONFIGURATION VARIABLES: EDIT BEFORE PASTING INTO YOUR WEBPAGE * * */
        var disqus_shortname = 'snowplow'; // required: replace example with your forum shortname

        /* * * DON'T EDIT BELOW THIS LINE * * */
        (function () {
            var s = document.createElement('script'); s.async = true;
            s.type = 'text/javascript';
            s.src = 'http://' + disqus_shortname + '.disqus.com/count.js';
            (document.getElementsByTagName('HEAD')[0] || document.getElementsByTagName('BODY')[0]).appendChild(s);
        }());
        </script>
</body>
</html>